# chapter17 스파크 배포 환경
- Spark 애플리케이션 실행에 필요한 인프라 구조에 대해서 알아보자
  - 클러스터 배포 시 선택사항
  - Spark가 지원하는 클러스터 매니저
  - 배포 시 고려사항과 배포 환경 설정
- Spark가 지원하는 모든 클러스터 매니저의 동작 방식은 대부분 유사함
- 하지만 사용자가 클러스터를 직접 설정하려면 각 클러스터 매니저의 설정을 잘 알아야 함
- 어떤 클러스터 매니저를 사용할지 결정하는 것 또한 매우 어려움
- 여러 클러스터 매니저로 다양한 클러스터를 구성하는 방법을 자세히 다루면 좋겠지만  
  이 책에서 모든 환경에서 발생할 수 있는 다양한 상황을 아주 자세하게 다루는 것은 불가능
- 이 장에서는 클러스터 매니저의 근본적인 차이점을 살펴보고 관련 자료를 소개함
- Spark 3.0.1 기준으로 4개의 클러스터 매니저를 제공함
  - Stand-Alone
  - Hadoop YARN
  - Apache Mesos
  - Kubernetes(신규 추가, 여기서는 다루지 않음)
- 이러한 클러스터 매니저는 Spark 애플리케이션을 배포해 실행할 수 있는 클러스터의 머신을 유지하고 관리
- 위 세 가지 클러스터 매니저는 Spark Application을 같은 방식으로 실행함
- 하지만 각 클러스터 매니저마다 추구하는 방향성이 다르기 때문에 반드시 장단점을 이해하고 상황에 맞게 사용해야 함
- 먼저 클러스터를 구성할 수 있는 환경을 알아보자

## 17.1 Spark 애플리케이션 실행을 위한 클러스터 환경
- Spark 클러스터를 구성할 수 있는 환경은 크게 두 가지로 나눌 수 있음
  - 설치형 클러스터(on-premise clutser)
  - 공개 클라우드(public cloud)

### 17.1.1 on-premise cluster 배포 환경
- 때로는 on-premise clutser 환경에서 Spark Application을 실행하는 것이 합리적일 수 있음
- 특히 자체 데이터센터를 운영하는 조직에 더욱 적합함
- 그 밖의 모든 상황에서 on-premise clutser 환경을 사용하면 trade-off가 존재함  
- on-premise clutser를 구축하면 사용 중인 하드웨어를 완전히 제어할 수 있으므로 특정 워크로드의 성능을 최적화 할 수 있음
- 하지만 Spark 같은 데이터 분석 워크로드에서는 몇 가지 문제가 발생할 수 있음  
  - 첫째, on-premise clutser의 크기는 제한적임  
    하지만 분석 워크로드에 필요한 자원은 상황에 따라 달라짐  
    예를 들어 클러스터를 너무 작게 만들면 신규 머신러닝 모델을 학습하는 Job을 실행하기 어려울 수 있음    
    반대로 클러스터를 너무 크게 만들면 사용하지 않는 자원이 많아짐  
  - 둘째, on-premise clutser는 HDFS이나 분산 키-값 저장소 같은 자체 저장소 시스템을 선택하고 운영해야 함  
    상황에 따라 지리적 복제(geo replication)및 재해 복구(disaster recovery) 체계도 함께 구축해야 함
- on-premise clutser를 사용한다면 자원 활용 문제를 해결할 수 있는 가장 좋은 방법은 클러스터 매니저를 사용하는 것
- 클러스터 매니저를 사용하면 다수의 Spark application을 실행 할 수 있고 Application의 자원을 동적으로 재할당할 수 있음
- 심지어 하나의 클러스터에서 Spark Application이 아닌 다른 프로그램을 실행할 수도 있음
- Spark가 지원하는 클러스터 매니저는 동시에 여러 어플리케이션을 실행할 수 있음
- 특히 YARN, Mesos는 동적 자원 공유를 Stand-alone 모드보다 잘 지원하며 Spark 이외의 애플리케이션도 실행할 수 있음
- 자원 공유를 제어하는 측면에서 on-premise clutser를 사용하는 것과 클라우드 환경의 클러스터를 사용하는 것은 큰 차이가 있음
- public cloud를 사용하면 애플리케이션에 맞는 규모의 클러스터를 얻을 수 있음
- on-premise clutser를 사용하면 여러 종류의 저장소를 선택할 수 있음. 하지만 이 책에서는 각 저장소가 가지고 있는 세부적인 장단점을 모두 다루지 않음
- 각 저장소의 정보를 알고 싶다면 관련 서적을 참고해라
- Spark는 Hadoop의 HDFS 같은 분산 파일 시스템과 Apache 카산드라 같은 key-value 저장소 시스템을 가장 많이 사용함
- 데이터를 수집하는 용도로 apache kafka 같은 스트리밍 메세지 버스 시스템을 사용
- 이러한 모든 시스템은 관리, 백업 그리고 지리적 복제 기능이 자체적으로 구현되어 있거나 상용 서드파티 도구를 이용해 다양한 수준으로 지원함
- <b>저장소를 선택할 때는 Spark 커넥터의 성능을 시험하고 관리 도구를 사용할 수 있는지 확인해야 함</b>

### 17.1.2 클라우드 배포 환경
- 초기 빅데이터 시스템은 설치형 클러스터에 적합하게 설계됨
- 하지만 시간이 지날수록 클라우드 환경은 일반적인 Spark 운영 플랫폼으로 자리 잡고 있음
- 클라우드 환경에서 빅데이터 워크로드를 실행하면 얻을 수 있는 몇 가지 장점이 있음
  - 첫째, 자원을 탄력적으로 늘이고 줄이는 것이 가능함  
    그렇기 때문에 몇 시간 동안 수백 대의 머신을 활용해야 하는 '괴물'같은 Job을 실행한다고 해도  
    사용한 만큼의 비용만 지불하면 됨
  - 일반적인 연산을 수행하는 경우에도 애플리케이션마다 다른 유형의 머신과 클러스터 규모를 선택할 수 있기 때문에  
    가격 대비 뛰어난 성능을 얻을 수 있음  
    예를 들어 딥러닝 작업이 필요한 경우에만 GPU 인스턴스를 할당받아 사용할 수 있음  
  - 둘째, 공개 클라우드 환경은 비용이 저렴하고 지리적 복제 기능을 지원하는 저장소를 제공하기 때문에  
    대규모 데이터를 쉽게 관리할 수 있음  
    AWS, Azure, GCP는 Apache Spark 뿐만 아니라 관리형 하둡 클러스터를 제공함  
- 클라우드 환경으로 전환하려는 많은 기업은 기존에 클러스터를 운영하는 방식 그대로 애플리케이션을 운영하려 함
- 하지만 고정된 크기의 클러스터와 파일 시스템은 유연성의 장점을 활용하지 못함
- 따라서 Amazon S3, Azure Blob, GCS와 같이 클러스터에서 분리된 글로벌 저장소 시스템을 사용하고  
  Spark 워크로드마다 별도의 클러스터를 동적으로 할당하는 것이 좋음
- 이렇게 연산 클러스터와 저장소 클러스터를 분리하면 연산이 필요한 경우에만 클러스터 비용을 지불하면 됨
- 또한 동적으로 크기 조절 가능, 하드웨어 종류가 다른 것들을 섞어서 사용도 가능
- 클라우드 환경에서는 on-premise 환경에서처럼 연산 관련 프로그램 및 환경을 관리할 필요가 없음
- 클라우드 저장소를 연동해 Spark를 실행하면 클라우드의 유연성, 비용 절감 효과, 관리 도구 등 다양한 장점을 활용할 수 있음

## 17.2 클러스터 매니저
- 클라우드 환경에서 제공하는 고급 관리 서비스를 사용하는 경우가 아니라면 Spark를 사용하기 위한 클러스터 매니저를 선택해야 함
- Spark가 지원하는 클러스터 매니저인 Stand-Alone cluster, Hadoop YARN, Mesos를 차례로 알아보자

### 17.2.1 stand-Alone 모드
- Spark의 스탠드-얼론 클러스터 매니저는 아파치 스파크 워크로드용으로 특별히 제작된 경량화 플랫폼
- 스탠드얼론 클러스터 매니저를 사용해 하나의 클러스터에서 다수의 Spark Application을 실행할 수 있음
- 또한 실행을 위한 간단한 인터페이스를 제공하며 대형 Spark 워크로드로 확장할 수 있음
- 다른 CM에 비해 제한적인 기능을 가지고 있음  
  Spark Application만 실행할 수 있다는 단점을 가지고 있음
- 하지만 클러스터 환경을 빠르게 구축해 Spark application을 실행해야 하거나 YARN이나 메소스를 사용해본 경험이 없다면 가장 좋은 선택지

#### 스탠드얼론 클러스터 시작하기
- 해당 CM 환경을 구성하려면 Cluster를 구성할 머신의 준비 과정을 필요로함
- 이는 네트워크 환경에서 클러스터를 구성하는 노드끼리 통신할 수 있어야 함을 의미
- 따라서 실행할 버전의 스파크를 내려받아 전체 노드에 설치해야 함
- 그런 다음 수동으로 실행하거나 Spark에 내장된 스크립트를 이용해 클러스터를 실행할 수 있음
- 수동으로 클러스터를 실행하려면 클러스터의 노드 중 하나에 다음 명령을 사용해 마스터 프로세스 실행
~~~
$SPARK_HOME/sbin/start-master.sh
~~~
- 앞 명령을 실행하면 CM의 마스터 프로세스가 실행됨
- 마스터 프로세스가 실행되면 spark://HOST:PORT 형식의 URI가 출력됨
- 마스터 프로세스의 URI는 워커노드를 실행할 때 사용됨. 클러스터의 애플리케이션 초기화 시 SparkSession의 --master 인수로  
  마스터 프로세스 URI를 사용할 수 있음
- 또한 마스터 프로세스 UI에서 마스터 프로세스의 URI를 확인할 수 있음
- 마스터 프로세스 UI의 기본 주소는 http://master-ip-address:8080임
- 클러스터를 실행할 머신에 로그인한 뒤, 실행시킬 스크립트와 마스터 프로세스 URI를 입력해 워커 노드 시작
- 마스터 노드는 워커 노드와 네트워크 통신이 가능해야 하며 마스터 프로세스 URI의 포트 역시 열려있어야 함
~~~
$SPARK_HOME/sbin/start-slave.sh <마스터-스파크-프로세스-URI>
~~~
- 전체 워커 노드에서 스크립트를 실행해 Spark Cluster를 사용할 수 있음
- 지금까지는 이 모든 과정을 수동으로 실행했는데, 자동으로 실행해주는 스크립트가 있음


## 용어 정리
- bus system
  - 데이터를 통신할 수 있게 해주는 시스템
- URI (Uniform Resource Identifier)
  - 인터넷 자원을 나타내는 고유 식별자 입니다. URI 에 I 가 Identifier 입니다. 인터넷에 있는 자료의 id 이다 , 라고 생각하면 좋을 것 같음