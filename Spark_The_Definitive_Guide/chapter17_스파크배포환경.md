# chapter17 스파크 배포 환경
- Spark 애플리케이션 실행에 필요한 인프라 구조에 대해서 알아보자
  - 클러스터 배포 시 선택사항
  - Spark가 지원하는 클러스터 매니저
  - 배포 시 고려사항과 배포 환경 설정
- Spark가 지원하는 모든 클러스터 매니저의 동작 방식은 대부분 유사함
- 하지만 사용자가 클러스터를 직접 설정하려면 각 클러스터 매니저의 설정을 잘 알아야 함
- 어떤 클러스터 매니저를 사용할지 결정하는 것 또한 매우 어려움
- 여러 클러스터 매니저로 다양한 클러스터를 구성하는 방법을 자세히 다루면 좋겠지만  
  이 책에서 모든 환경에서 발생할 수 있는 다양한 상황을 아주 자세하게 다루는 것은 불가능
- 이 장에서는 클러스터 매니저의 근본적인 차이점을 살펴보고 관련 자료를 소개함
- Spark 3.0.1 기준으로 4개의 클러스터 매니저를 제공함
  - Stand-Alone
  - Hadoop YARN
  - Apache Mesos
  - Kubernetes(신규 추가, 여기서는 다루지 않음)
- 이러한 클러스터 매니저는 Spark 애플리케이션을 배포해 실행할 수 있는 클러스터의 머신을 유지하고 관리
- 위 세 가지 클러스터 매니저는 Spark Application을 같은 방식으로 실행함
- 하지만 각 클러스터 매니저마다 추구하는 방향성이 다르기 때문에 반드시 장단점을 이해하고 상황에 맞게 사용해야 함
- 먼저 클러스터를 구성할 수 있는 환경을 알아보자

## 17.1 Spark 애플리케이션 실행을 위한 클러스터 환경
- Spark 클러스터를 구성할 수 있는 환경은 크게 두 가지로 나눌 수 있음
  - 설치형 클러스터(on-premise clutser)
  - 공개 클라우드(public cloud)

### 17.1.1 on-premise cluster 배포 환경
- 때로는 on-premise clutser 환경에서 Spark Application을 실행하는 것이 합리적일 수 있음
- 특히 자체 데이터센터를 운영하는 조직에 더욱 적합함
- 그 밖의 모든 상황에서 on-premise clutser 환경을 사용하면 trade-off가 존재함  
- on-premise clutser를 구축하면 사용 중인 하드웨어를 완전히 제어할 수 있으므로 특정 워크로드의 성능을 최적화 할 수 있음
- 하지만 Spark 같은 데이터 분석 워크로드에서는 몇 가지 문제가 발생할 수 있음  
  - 첫째, on-premise clutser의 크기는 제한적임  
    하지만 분석 워크로드에 필요한 자원은 상황에 따라 달라짐  
    예를 들어 클러스터를 너무 작게 만들면 신규 머신러닝 모델을 학습하는 Job을 실행하기 어려울 수 있음    
    반대로 클러스터를 너무 크게 만들면 사용하지 않는 자원이 많아짐  
  - 둘째, on-premise clutser는 HDFS이나 분산 키-값 저장소 같은 자체 저장소 시스템을 선택하고 운영해야 함  
    상황에 따라 지리적 복제(geo replication)및 재해 복구(disaster recovery) 체계도 함께 구축해야 함
- on-premise clutser를 사용한다면 자원 활용 문제를 해결할 수 있는 가장 좋은 방법은 클러스터 매니저를 사용하는 것
- 클러스터 매니저를 사용하면 다수의 Spark application을 실행 할 수 있고 Application의 자원을 동적으로 재할당할 수 있음
- 심지어 하나의 클러스터에서 Spark Application이 아닌 다른 프로그램을 실행할 수도 있음
- Spark가 지원하는 클러스터 매니저는 동시에 여러 어플리케이션을 실행할 수 있음
- 특히 YARN, Mesos는 동적 자원 공유를 Stand-alone 모드보다 잘 지원하며 Spark 이외의 애플리케이션도 실행할 수 있음
- 자원 공유를 제어하는 측면에서 on-premise clutser를 사용하는 것과 클라우드 환경의 클러스터를 사용하는 것은 큰 차이가 있음
- public cloud를 사용하면 애플리케이션에 맞는 규모의 클러스터를 얻을 수 있음
- on-premise clutser를 사용하면 여러 종류의 저장소를 선택할 수 있음. 하지만 이 책에서는 각 저장소가 가지고 있는 세부적인 장단점을 모두 다루지 않음
- 각 저장소의 정보를 알고 싶다면 관련 서적을 참고해라
- Spark는 Hadoop의 HDFS 같은 분산 파일 시스템과 Apache 카산드라 같은 key-value 저장소 시스템을 가장 많이 사용함
- 데이터를 수집하는 용도로 apache kafka 같은 스트리밍 메세지 버스 시스템을 사용
- 이러한 모든 시스템은 관리, 백업 그리고 지리적 복제 기능이 자체적으로 구현되어 있거나 상용 서드파티 도구를 이용해 다양한 수준으로 지원함
- <b>저장소를 선택할 때는 Spark 커넥터의 성능을 시험하고 관리 도구를 사용할 수 있는지 확인해야 함</b>

### 17.1.2 클라우드 배포 환경
- 초기 빅데이터 시스템은 설치형 클러스터에 적합하게 설계됨
- 하지만 시간이 지날수록 클라우드 환경은 일반적인 Spark 운영 플랫폼으로 자리 잡고 있음
- 클라우드 환경에서 빅데이터 워크로드를 실행하면 얻을 수 있는 몇 가지 장점이 있음
  - 첫째, 자원을 탄력적으로 늘이고 줄이는 것이 가능함  
    그렇기 때문에 몇 시간 동안 수백 대의 머신을 활용해야 하는 '괴물'같은 Job을 실행한다고 해도  
    사용한 만큼의 비용만 지불하면 됨
  - 일반적인 연산을 수행하는 경우에도 애플리케이션마다 다른 유형의 머신과 클러스터 규모를 선택할 수 있기 때문에  
    가격 대비 뛰어난 성능을 얻을 수 있음  
    예를 들어 딥러닝 작업이 필요한 경우에만 GPU 인스턴스를 할당받아 사용할 수 있음  
  - 둘째, 공개 클라우드 환경은 비용이 저렴하고 지리적 복제 기능을 지원하는 저장소를 제공하기 때문에  
    대규모 데이터를 쉽게 관리할 수 있음  
    AWS, Azure, GCP는 Apache Spark 뿐만 아니라 관리형 하둡 클러스터를 제공함  
- 클라우드 환경으로 전환하려는 많은 기업은 기존에 클러스터를 운영하는 방식 그대로 애플리케이션을 운영하려 함
- 하지만 고정된 크기의 클러스터와 파일 시스템은 유연성의 장점을 활용하지 못함
- 따라서 Amazon S3, Azure Blob, GCS와 같이 클러스터에서 분리된 글로벌 저장소 시스템을 사용하고  
  Spark 워크로드마다 별도의 클러스터를 동적으로 할당하는 것이 좋음
- 이렇게 연산 클러스터와 저장소 클러스터를 분리하면 연산이 필요한 경우에만 클러스터 비용을 지불하면 됨
- 또한 동적으로 크기 조절 가능, 하드웨어 종류가 다른 것들을 섞어서 사용도 가능
- 클라우드 환경에서는 on-premise 환경에서처럼 연산 관련 프로그램 및 환경을 관리할 필요가 없음
- 클라우드 저장소를 연동해 Spark를 실행하면 클라우드의 유연성, 비용 절감 효과, 관리 도구 등 다양한 장점을 활용할 수 있음

## 17.2 클러스터 매니저
- 클라우드 환경에서 제공하는 고급 관리 서비스를 사용하는 경우가 아니라면 Spark를 사용하기 위한 클러스터 매니저를 선택해야 함
- Spark가 지원하는 클러스터 매니저인 Stand-Alone cluster, Hadoop YARN, Mesos를 차례로 알아보자

### 17.2.1 stand-Alone 모드
- Spark의 스탠드-얼론 클러스터 매니저는 아파치 스파크 워크로드용으로 특별히 제작된 경량화 플랫폼
- 스탠드얼론 클러스터 매니저를 사용해 하나의 클러스터에서 다수의 Spark Application을 실행할 수 있음
- 또한 실행을 위한 간단한 인터페이스를 제공하며 대형 Spark 워크로드로 확장할 수 있음
- 다른 CM에 비해 제한적인 기능을 가지고 있음  
  Spark Application만 실행할 수 있다는 단점을 가지고 있음
- 하지만 클러스터 환경을 빠르게 구축해 Spark application을 실행해야 하거나 YARN이나 메소스를 사용해본 경험이 없다면 가장 좋은 선택지

#### 스탠드얼론 클러스터 시작하기
- 해당 CM 환경을 구성하려면 Cluster를 구성할 머신의 준비 과정을 필요로함
- 이는 네트워크 환경에서 클러스터를 구성하는 노드끼리 통신할 수 있어야 함을 의미
- 따라서 실행할 버전의 스파크를 내려받아 전체 노드에 설치해야 함
- 그런 다음 수동으로 실행하거나 Spark에 내장된 스크립트를 이용해 클러스터를 실행할 수 있음
- 수동으로 클러스터를 실행하려면 클러스터의 노드 중 하나에 다음 명령을 사용해 마스터 프로세스 실행
~~~
$SPARK_HOME/sbin/start-master.sh
~~~
- 앞 명령을 실행하면 CM의 마스터 프로세스가 실행됨
- 마스터 프로세스가 실행되면 spark://HOST:PORT 형식의 URI가 출력됨
- 마스터 프로세스의 URI는 워커노드를 실행할 때 사용됨. 클러스터의 애플리케이션 초기화 시 SparkSession의 --master 인수로  
  마스터 프로세스 URI를 사용할 수 있음
- 또한 마스터 프로세스 UI에서 마스터 프로세스의 URI를 확인할 수 있음
- 마스터 프로세스 UI의 기본 주소는 http://master-ip-address:8080임
- 클러스터를 실행할 머신에 로그인한 뒤, 실행시킬 스크립트와 마스터 프로세스 URI를 입력해 워커 노드 시작
- 마스터 노드는 워커 노드와 네트워크 통신이 가능해야 하며 마스터 프로세스 URI의 포트 역시 열려있어야 함
~~~
$SPARK_HOME/sbin/start-slave.sh <마스터-스파크-프로세스-URI>
~~~
- 전체 워커 노드에서 스크립트를 실행해 Spark Cluster를 사용할 수 있음
- 지금까지는 이 모든 과정을 수동으로 실행했는데, 자동으로 실행해주는 스크립트가 있음

#### 스크립트를 이용한 스탠드얼론 클러스터 시작하기
- 시작 스크립트를 설정해 스탠드얼론 클러스터의 시작을 자동화할 수 있음
- 이를 위해 Spark가 설치된 디렉터리 하위에 `conf/slaves` 파일을 생성함
- slaves 파일에 Spark 워커로 사용할 모든 머신의 호스트명을 한 줄에 하나씩 기록함
- 이 파일이 없으면 모든 데몬이 로컬에서 실행됨
- 실제로 클러스터를 실행할 때 마스터 머신은 모든 워커 머신에 SSH(Secure Shell, 보안 셸)를 이용해 접근함
- SSH는 병렬로 실행되며 개인 키(private key)를 이용해 비밀번호 없이 로그인하는 방식(password-less)를 사용
- 만약 이 방법을 쓸 수 없다면 SPARK_SSH_FOREGROUD 환경변수를 설정해 워커 노드에 접근할 때마다 비밀번호를 입력
- slave 파일을 설정하고 나면 하둡 배포 스크림트 기반의 다음 셸 스크립트를 사용해 클러스터를 시작하거나 중지시킬 수 있음
- 이들 스크립트는 `$SPARK_HOME/sbin` 디렉터리에 들어 있음
  - `$SPARK_HOME/sbin/start-master.sh` : 스크립트를 실행한 머신에서 마스터 인스턴스 시작
  - `$SPARK_HOME/sbin/start-slaves.sh` : conf/slaves 파일에 명시된 각 머신에서 slave instance를 시작
  - `$SPARK_HOME/sbin/start-slave.sh` : 스크립트를 실행한 머신에서 슬레이브 인스턴스를 시작
  - `$SPARK_HOME/sbin/start-all.sh` : 마스터 인스턴스를 시작하고 conf/slaves 파일에 명시된 각 머신에서 슬레이브 인스턴스를 시작
  - `$SPARK_HOME/sbin/stop-master.sh` : bin/start-master.sh 스크립트로 시작한 마스터 인스턴스를 중지시킴
  - `$SPARK_HOME/sbin/stop-slaves.sh` : conf/slaves 파일에 명시한 각 머신에서 slave 인스턴스 중지
  - `$SPARK_HOME/sbin/stop-all.sh` : 마스터 인스턴스를 중지시키고 conf/slaves 파일에 명시한 각 머신에서 슬레이브 인스턴스를 중지 시킴

#### 스탠드얼론 클러스터 설정
- 스탠드얼론 클러스터는 애플리케이션 튜닝에 필요한 여러 가지 설정을 가지고 있음
- 이러한 설정은 종료된 애플리케이션의 워커별 작업 파일에서부터 워커와 코어의 메모리에 이르기까지 모든 것을 제어함
- 설정은 환경변수나 애플리케이션의 속성으로 정의함
- 자세한 내용은 Spark의 공식 문서의 스탠드얼론 환경변수 표를 참고하자

#### 애플리케이션 제출하기
- 클러스터를 생성하면 마스터 프로세스의 URI를 이용해 마스터 노드나 `spark-submit` 명령을 사용할 수 있는 머신에서 애플리케이션을 제출할 수 있음
- 16.4절 '애플리케이션 시작하기'에서 스탠드얼론 모드와 관련된 특정 명령행 인수를 확인할 수 있음

### 17.2.2 YARN에서 Spark 실행하기
- 하둡 YARN은 잡 스케줄링과 클러스터 자원 관리용 프레임워크
- <b>Spark를 '하둡 에코시스템'의 일부로 착각해 잘못 분류하는 경우가 많음. 하지만 Spark는 하둡과 거의 관련이 없음</b>
- Spark는 기본적으로 하둡 YARN 클러스터 매니저를 지원하지만 하둡 자체가 필요한 것은 아님
- `spark-submit` 명령의 `--master` 인수를 yarn으로 지정해 하둡 YARN 클러스터에서 Spark Job을 실행할 수 있음
- 클러스터 동작 방식을 제어할 수 있는 여러 가지 기능을 제공
- 하둡 YARN은 다양한 실행 프레임워크를 지원하는 통합 스케줄러이므로, 스탠드얼론 클러스터 매니저에 비해 많은 기능을 사용할 수 있음

#### 애플리케이션 제출하기
- YARN 클러스터와 다른 배포 환경과의 가장 큰 차이점은 `--master` 인수의 값을 `yarn`으로 지정한다는 것
- Spark는 `HADOOP_CONF_DIR`이나 `YARN_CONF_DIR` 환경변수를 통해 `YARN` 설정 파일을 찾아냄
- 이들 환경변수를 하둡의 환경 설정 디렉터리 경로에 설정하면 `spark-submit` 명령 실행 가능
- YARN에서는 두 가지 배포 모드로 Spark application을 실행할 수 있음
- cluster 모드는 YARN 클러스터에서 스파크 드라이버 프로세스를 관리하며 클라이언트는 애플리케이션을 생성한 다음 즉시 종료
- 반면 <b>client 모드는 드라이버가 클라이언트 프로세스에서 실행됨</b> 따라서 YARN은 마스터 노드를 관리하지 않으며  
  애플리케이션의 익스큐터 자원을 배분하는 역할만함  
- 또한 cluster 모드에서는 Spark application을 실행한 노드가 아닌 다른 노드에서  Spark Job이 실행될 수 있음
- 그러므로 라이브러리와 외부 jar 파일을 클러스터 노드에 수동으로 배포하거나 spark-submit 명령의 --jars 인수에 명시해 배포해야 함

### 17.2.3 YARN 환경의 Spark application 설정하기
- YARN에 Spark application을 배포하려면 다양한 설정과 Spark application에 미치는 영향을 이해해야 함
- 기본 설정 시 참고할 만한 몇 가지 예제와 Spark application 실행에 필요한 주요 설정을 알아보자

#### 하둡 설정
- Spark를 이용해 HDFS의 파일을 읽고 쓰려면 Spark 클래스패스에 두 개의 하둡 설정 파일을 포함시켜야 함
- 하나는 HDFS 클라이언트의 동작 방식을 결정하는 `hdfs-site.xml` 파일이고, 다른 하나는 기본 파일 시스템의 이름을 설정하는  
  `core-site.xml` 파일
- 하둡 버전에 따라 위치가 가변적이지만 보통 `etc/hadoop/conf` 하위 설정 파일이 존재함
- 일부 도구는 이러한 설정 파일을 즉석에서 만듬. 따라서 관리형 서비스에서 하둡 설정 파일을 어떻게 배포하는지 이해하는 것이 중요
- Spark에서 하둡 설정 파일을 사용하려면 `$SPARK_HOME/spark-env.sh` 파일의 `HADOOP_CONF_DIR` 변숫값을 하둡 설정 파일 경로로 지정하거나  
  `spark-submit` 명령을 사용해 애플리케이션을 실행할 때 환경변수로 지정해야 함

#### YARN 애플리케이션 속성
- 하둡 설정이나 기능 중 YARN의 실행과 보안에 관련된 설정은 스파크에 영향을 미침
- 관련 설정은 Spark 공식 문서에서 YARN 설정 표를 참고하자

### 17.2.4 메소스에서 Spark 실행하기
- 메소스 프로젝트의 정의는 다음과 같음
- '아파치 메소스는 CPU, 메모리, 저장소 그리고 다른 연산 자원을 머신에서 추상화합니다. 이를 통해 내고장성(fault-tolerant) 및  
  탄력적 분산 시스템(elastic distributed system)을 쉽게 구성하고 효과적으로 실행할 수 있습니다'
- 메소스는 spark처럼 짧게 실행되는 애플리케이션을 관리할 수 있음  
  또한 웹 애플리케이션이나 다른 자원 인터페이스 등 오래 실행되는 애플리케이션까지 관리할 수 있는 데이터센터 규모의 클러스터 매니저를 지향
- 메소스는 Spark에서 지원하는 클러스터 매니저 중 가장 무거움
- 대규모의 메소스 배포 환경이 있는 경우에만 사용하는 것이 좋음
- 하지만 좋은 클러스터 매니저임은 분명함
- 메소스는 거대한 인프라 구조임

### 17.2.5 보안 관련 설정
- Spark는 신뢰도가 낮은 환경에서 애플리케이션을 안전하게 실행할 수 있도록 저수준 API 기능을 제공
- 이 설정의 대부분은 Spark 외부의 실행 환경과 관련 있음
- 보안 관련 설정은 주로 통신 방식과 관련 있음. 여기에서는 인증, 네트워크 구간 암호화, TLS와 SSL 설정할 수 있음  
  이를 통해 안전한 환경에서 Spark를 실행할 수 있음

### 17.2.6 클러스터 네트워크 설정
- 클러스터 네트워크 설정은 더 나은 Spark 실행 환경을 위해 시도해볼 만한 튜닝 설정
- 이는 클러스터 노드 사이에서 proxy를 사용하기 위해 Spark 클러스터에 사용자 정의 배포 설정을 적용하는 경우에 도움이 됨
- Spark 성능을 높이고 싶다면 설정을 무작정 적용하지 말고 사용자가 정의한 배포 시나리오에 맞게 적용해야 함
- 클러스터 네트워크 설정과 관련된 전체 내용은 Spark 공식 문서에서 네트워킹 설정 표를 참고하자

### 17.2.7 애플리케이션 스케줄링
- Spark는 여러 연산 과정에서 필요한 자원을 스케줄링할 수 있는 몇 가지 기능을 제공함
- 첫째, 각 Spark application은 독립적인 익스큐터 프로세스를 실행  
  클러스터 매니저는 Spark application 전체에 대한 스케줄링 기능을 제공
- 둘째, Spark application에서 여러 개의 Job을 다른 스레드가 제출한 경우 동시에 실행할 수 있음  
  이 동작 방식은 네트워크를 통한 요청에 응답하는 애플리케이션에 적합
- Spark는 애플리케이션에서 자원을 스케줄링할 수 있도록 fair scheduler 기능 제공
- 단일 클러스터를 공유해 다수의 사용자가 Spark application을 실행하면 클러스터 매니저에 따라 자원 할당을  
  관리할 수 있는 여러 옵션이 있음
- 모든 클러스터 매니저에서 사용할 수 있는 가장 간단한 방법은 자원을 고정된 크기로 나누는 것  
  이 방법을 사용하면 각 애플리케이션이 사용할 수 있는 최대 자원이 결정됨
- Spark 애플리케이션은 종료 전까지 해당 자원을 점유함
- `spark-submit` 명령에는 특정 애플리케이션의 자원 할당을 제어하기 위한 여러 설정값이 있음
- <b>동적 할당</b> 기능을 이용하면 대기 중인 태스크 수에 따라 애플리케이션을 동적으로 확장하고 축소할 수 있음
- 만약 익스큐터의 자원과 메모리를 공유하려면 단일 Spark 애플리케이션을 실행하고 스레드 스케줄링을 이용해 병렬로 요청 처리함

#### 동적 할당
- 하나의 클러스터에서 여러 Spark application을 실행하려면 워크로드에 따라 애플리케이션이 점유하는 자원을  
  동적으로 조정해야함. Spark는 이러한 매커니즘을 제공함
- <b>동적 할당은 사용자 애플리케이션이 사용하지 않는 자원을 클러스터에 반환하고 필요할 때 다시 요청하는 방식을 의미함</b>
- 이 기능은 다수의 애플리케이션이 Spark 클러스터의 자원을 함께 사용해야 하는 경우에 특히 유용
- 이 기능은 스탠드얼론, YARN, 메소스 coarse-grained 모드에서 사용할 수 있음. 기본값은 '사용하지 않음'임
- '사용함'으로 변경하고 싶다면 두 가지 설정을 변경해야 함
  - 첫째, 사용자 애플리케이션에서 `spark.dynamicAllocation.enabled` 속성을 true로 지정
  - 둘째, 클러스터를 구성하는 워커 노드에서 외부 셔플 서비스를 사용하도록 설정해야 함  
    또한 애플리케이션에서 `spark.shuffle.service.enabled`를 true로 지정 
- 외부 셔플 서비스를 사용하면 익스큐터가 제거될 때 셔플 파일을 삭제하지 않아도 됨
- 이 기능은 클러스터 매니저마다 설정이 다름
   
## 17.3 기타 고려사항
- Spark 애플리케이션을 배포할 때 고려해야 하는 몇 가지 사항이 있음
- 앞으로 설명할 내용은 클러스터 매니저를 선택하고 설치하는 데 영향을 주기 때문에 각 배포 환경을 비교할 때 반드시 고려해야 함
- <b>가장 우선으로 생각해야 할 것은 애플리케이션의 개수와 유형</b>
- 예를 들어 YARN은 HDFS를 사용하는 애플리케이션을 실행할 때 가장 적합하지만 그 외의 경우에는 잘 사용하지 않음
- YARN은 HDFS의 정보를 사용하도록 설계되었기 때문에 클라우드 환경을 제대로 지원하지 못함
- 또한 연산용 클러스터와 저장소 클러스터가 강하게 결합되어 있음  
  즉, 클러스터를 확장할 때 연산용 클러스터와 저장소 클러스터를 동시에 확장해야 함
- 메소스는 YARN이 가진 개념을 조금 더 개선하였으며 다양한 애플리케이션 유형을 지원함
- 하지만 메소스는 더 큰 규모의 클러스터에 적합함. 그리므로 Spark 애플리케이션만 실행하려고  
  메소스 클러스터를 구축하는 것은 바람직하지 않음
- Spark 스탠드얼론 클러스터는 가장 가벼운 클러스터 매니저이며 비교적 이해와 활용이 쉬움
- 하지만 더 많은 애플리케이션을 관리하는 인프라 구조를 구축해야 한다면 YARN이나 메소스를 사용하는 것이 훨씬 더 나을 수 있음
- 다양한 Spark 버전을 관리하는 것 또한 상당히 힘든 문제  
  다양한 Spark 버전으로 된 여러 Spark application을 실행하려면 버전별 설정 스크립트를 관리하는 데 많은 시간을 할애해야 함
- 아니면 다양한 버전의 Spark 애플리케이션을 실행할 수 없도록 Spark 버전에 제한을 걸어야 함
- 클러스터 매니저에 상관없이 애플리케이션 디버깅에 필요한 로그를 기록하는 방식을 결정해야 함
- YARN과 메소스는 로그 기록 기능을 기본으로 제공함. 반면 스탠드얼론 모드를 사용하는 경우라면 약간의 수정이 필요
- 테이블 카탈로그 같은 저장된 데이터셋의 메타데이터를 관리하기 위해 메타스토어 사용을 고려해야 함
- 10장에서 테이블을 만들고 유지 관리하기 위해 스파크 SQL 내부적으로 어떤 일이 발생하는지 살펴보았음
- 워크로드의 특성에 따라 외부 셔플 서비스를 사용해야 할 수도 있음
- 일반적으로 Spark는 셔플 블록을 특정 노드의 로컬 디스크에 저장  
- 외부 셔플 서비스를 이용하면 모든 익스큐터가 외부 셔플 서비스에 셔플 블록을 저장함
  따라서 익스큐터를 임의로 제거해도 다른 애플리케이션의 셔플 결과를 사용할 수 있음
- 마지막으로 클러스터에서 실행되는 Spark Job을 디버깅하려면 최소한 기본적인 모니터링 솔루션이 필요  
  모니터링 솔루션은 클러스터 매니저 옵션에 따라 달라짐  
  모니터링과 디버깅은 다음장에서 자세히 알아보자


## 용어 정리
- bus system
  - 데이터를 통신할 수 있게 해주는 시스템
- URI (Uniform Resource Identifier)
  - 인터넷 자원을 나타내는 고유 식별자 입니다. URI 에 I 가 Identifier 입니다. 인터넷에 있는 자료의 id 이다 , 라고 생각하면 좋을 것 같음
- SSH(Secure Shell protocol)  
  - 네트워크 프로토콜 중 하나로, 컴퓨터와 컴퓨터가 인터넷과 같은 Public Network를 통해 서로 통신을 할 때  
    보안적으로 안전하게 통신하기 위해 사용하는 프로토콜  
  - 대표적인 사용 예는, 데이터 전송, 원격 제어가 있음  
  - 데이터 전송의 예로는 github에서 원격 저장소에 push 할 때 SSH를 이용해 push 하게 됨
  - 원격 제어의 예로는 AWS의 인스턴스 서버에 접속하여 해당 머신에 명령을 내리기 위하여 SSH 접속 해야함
- 프록시(proxy)
  - '대리'라는 의미로, 네트워크 기술에서는 프로토콜에 있어서 대리 응답 등에서 친숙한 개념  
    보안 분야에서는 주로 보안상의 이유로 직접 통신할 수 없는 두 점 사이에서 통신을 할 경우  
    그 상이에 있어서 중계기로서 대리로 통신을 수행하는 기능을 가리킴
