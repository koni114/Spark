# chapter18 모니터링과 디버깅
- 이번 장에서는 Spark Job의 생애 주기를 추적하는 방법을 이해하기 위해  
  예제 쿼리와 Spark UI를 함께 살펴보자
- 이 장의 예제는 디버깅 방법과 오류 발생 지점을 이해하는 데 도움이 될 것임

## 18.1 모니터링 범위
- Spark Job의 오류 발생 지점을 파악하려면 Spark Job을 모니터링 해야함
- 모니터링 대상과 모니터링에 필요한 옵션을 알아야 함. 먼저 모니터링 대상 컴포넌트에 대해 알아보자
  - Spark application Job  
  클러스터에서 사용자 애플리케이션이 실행되는 상황을 파악하거나 디버깅하려면 <b>가장 먼저 Spark UI와 Spark 로그를 확인해야 함</b>  
  해당 UI와 로그는 RDD와 쿼리실행계획 같은 개념적 수준의 정보를 제공  
  - JVM  
  Spark는 모든 익스큐터를 개별 JVM에서 실행함  
  따라서 코드가 실행되는 과정을 이해하기 위해 각 가상 머신을 모니터링 해야함  
  JVM 도구에는 스택 트레이스(stack trace)를 제공하는 jstack, 힙 덤프(heap dump)를 생성하는 jmap, 시계열 통계 리포트를 제공하는 jstat, 다양한 JVM 속성 변수를 시각화된 방식으로 탐색할 수 있는 jconsole 등이 있음.  
  이는 JVM 내부 동작 방식을 이해하는데 도움이 됨  
  jvisualvm을 이용해 Spark Job의 동작 특성을 알아볼 수도 있음  
  <b>저수준 디버깅이 필요하다면 JVM 도구가 유용함</b>
  - OS와 머신  
  JVM은 OS에서 실행됨. 따라서 머신의 상태를 모니터링해 정상 작동 중인지를 확인하는 것은 매우 중요  
  CPU, 네트워크, I/O 등의 자원에 대한 모니터링도 함께 해야 함  
  이러한 모니터링 요소들은 클러스터 수준 모니터링 솔루션에서 확인 가능  
  `dstat`, `iostat`, `iotop` 같은 명령을 사용하면 더 세밀하게 모니터링 할 수 있음
  - 클러스터  
  Spark application이 실행되는 클러스터도 모니터링 해야 함  
  여기서는 YARN, 메소스, 스탠드얼론 매니저가 모니터링 대상  
  모니터링 솔루션을 활용하면 클러스터가 동작하지 않는 상황을 빠르게 알 수 있음  
  인기 있는 클러스터 모니터링 도구로는 강글리아(Ganglia), 프로메테우스(Prometheus)가 있음

## 18.2 모니터링 대상
- 모니터링 대상을 간락하게 살펴본 다음, Spark application을 모니터링하고 디버깅하는 방법을 알아보자
- 모니터링 대상은 다음과 같이 크게 두 가지로 나눌 수 있음
  - <b>실행 중인 사용자 어플리케이션의 프로세스(CPU, 메모리 사용률 등)</b> 
  - <b>프로세스 내부에서의 쿼리 실행 과정(ex) Job과 Task)</b>

### 18.2.1 드라이버와 익스큐터 프로세스
- Spark 애플리케이션 모니터링시, 드라이버를 유심히 관찰 해야 함
- 드라이버는 모든 애플리케이션의 상태와 안정적인 실행 여부 확인 가능  
  만약 한 대의 머신이나 단일 JVM을 모니터링 해야 한다면 드라이버를 모니터링 해야 함
- 익스큐터 상태를 모니터링 하는 것도 매우 중요
- Spark는 수월한 모니터링을 지원하기 위해 드롭위자드 매트릭 라이브러리(Dropwizard Metrics Library) 기반의 매트릭 시스템(metric system)을 갖추고 있음
- 매트릭 시스템은 `$SPARK_HOME/conf/metrics.properties` 파일을 생성해 구성할 수 있음
- 또한 `spark.metric.conf` 속성의 값을 지정해 매트릭 시스템 설정 파일의 경로를 변경할 수도 있음
- 이러한 매트릭은 강글리아 같은 클러스터 모니터링 솔루션을 포함해 다양한 시스템으로 내보낼 수 있음

### 18.2.2 쿼리, 잡, 스테이지, 태스크
- 드라이버와 익스큐터 프로세스에 대한 모니터링도 중요하지만 특정 쿼리에서 무슨 일이 일어나고 있는지 알아야 할 때도 있음
- <b>Spark는 쿼리, 잡, 스테이지, 태스크의 개념을 가지고 있으며 각각의 정보를 확인할 수 있음</b>
- 이 정보는 클러스터 특정 시점에서 실행되는 정보 파악이 가능하며, 성능 개선/디버깅시 유용함
- 다음으로는 가장 많이 사용하는 방법인 Spark Log와 Spark UI를 통한 모니터링을 알아보자

## 18.3 Spark 로그
- Spark를 가장 상세하게 모니터링하는 방법 중 하나는 Log File을 살펴보는 것
- Spark 애플리케이션의 로그나 Spark 자체의 로그에서 발견된 이상한 이벤트는 Job의 실패 지점이나 원인을 파악하는 데 큰 도움이 됨
- 이 책에서 제공하는 예제 탬플릿을 사용하면 상관관계를 쉽게 파악할 수 있음(https://bit.ly/2QKoyM6)
  탬플릿에 설정된 로깅 프레임워크를 통해 Spark 로그와 사용자 애플리케이션 로그를 모두 확인 가능
- 파이썬은 Spark의 자바 기반 로깅 라이브러리를 사용할 수 없으므로 파이썬의 `logging` 모듈 또는 `print` 구문을 사용해 표준 오류로 결과를 출력해야 함
- Spark의 로그 수준을 변경하려면 다음과 같은 명령 실행
~~~scala
spark.sparkContext.setLogLevel("INFO")
~~~
- 위 설정으로 로그 수준에 맞는 Spark 로그를 확인할 수 있음
- 만약 로깅 프레임워크를 사용한다면 Spark log와 함께 사용자가 직접 필요한 정보를 로그로 기록할 수 있으므로, Spark와 Spark application을 모두 점검할 수 있음
- 로컬 모드로 애플링케이션을 실행한다면 로그 자체가 표준 오류로 출력되지만, 클러스터에서 Spark를 실행한다면 클러스터 매니저로 파일에 로그를 저장할 수 있음
- 클러스터 매니저 공식 문서에 로그 파일을 찾는 방법이 나와 있음
- 일반적으로 클러스터 매니저의 웹 UI로 로그를 조회할 수 있음
- 클라우드 환경에서 실행되는 경우 머신이 고장 나거나 전원이 내려갔다면 로그가 기록된 머신에서 기록된 로그를 내려받아 문제점을 확인할 수 있음

## 18.4 Spark UI
- 스파크 UI는 실행 중인 애플리케이션과 Spark 워크로드에 대한 평가지표를 모니터링할 수 있는 화면 제공
- 모든 SparkContext는 실행 시 애플리케이션과 관련된 유용한 정보를 제공하는 웹 UI를 4040 포트로 기본 실행함
- 예를 들어 Spark를 로컬 모드로 실행할 때 로컬 머신에서 실행 중인 Spark Application의 웹 UI는 http://localhost:4040에 접속해서 볼 수 있음
- 다수의 애플리케이션 실행 시 Spark는 포트 번호를 순차적으로 증가(4041, 4042..)시키면서 웹 UI를 실행 
- 클러스터 매니저의 UI는 애플리케이션별 웹 UI로 이동할 수 있는 링크 제공
- 다음은 Spark UI에서 사용 가능한 모든 탭을 나타냄
  - Jobs : Spark Job에 대한 정보 제공
  - Stages : 개별 스테이지와 관련된 정보 제공
  - Storage : Spark application에 캐싱된 정보와 데이터 정보 제공
  - Environment : Spark application의 구성과 설정 관련 정보를 제공
  - Executors : 애플리케이션에서 사용 중인 익스큐터의 상세 정보 제공
  - SQL : SQL과 DataFrame을 포함한 구조적 API 쿼리 정보를 제공
- 다음 예제에서는 쿼리 처리 과정을 세부적으로 파악하는 방법을 알아보자
- 새로운 Spark-shell을 시작하고 다음 코드를 실행하면 Spark UI로 실행 과정 추적 가능  
( http://localhost:4040로 접속)
~~~scala
    spark.read.format("csv")
    .option("header", "true")
    .load("C:/Spark-The-Definitive-Guide-master/data/retail-data/all/online-retail-dataset.csv")
    .repartition(2)
    .selectExpr("instr(Description, 'GLASS')>= 1 as is_glass")
    .groupBy("is_glass")
    .count()
    .collect()

~~~
- 위 코드 예제는 여러 값을 가진 3개의 로우를 결과로 반환
- 예제에서는 SQL 쿼리를 실행했으므로 SQL 탭을 확인해보면 다음 그림과 같은 유사한 화면 확인 가능

![img](https://github.com/koni114/Spark/blob/main/Spark_The_Definitive_Guide/imgs/Spark_monitoring1.JPG)

- Spark 스테이지의 지향성 비순환 그래프를 먼저 살펴보자
- SQL 탭의 파란색 상자는 Spark Task의 스테이지를 나타냄
- 이러한 스테이지의 전체 그룹은 Spark Job을 나타냄
- 단계별로 무슨 일이 발생하는지 파악하기 위해 스테이지별로 자세히 살펴보자
- `WholeStateCodegen`으로 표시된 상단의 상자는 CSV 파일을 모두 스캔하는 스테이지를 나타냄
- 하단의 상자는 파티션 재분배로 발생하는 셔플 스테이지(Exchange)를 나타냄
- 이 스테이지에서 원본 데이터셋(아직 파티션 수는 결정되지 않음)이 두 개의 파티션으로 분할 됨

![img](https://github.com/koni114/Spark/blob/main/Spark_The_Definitive_Guide/imgs/Spark_monitoring2.JPG)

- 다음 단계에서는 프로젝션(컬럼 선택/추가/필터링)과 집계 수행 
- 아래 그림을 보면 6개의 로우가 반환된 것을 확인 가능
- Spark는 최종 단계를 위한 준비 작업으로 데이터를 셔플하기 전 파티션별로 집계 수행
- 이번 예제에서는 해시 기반의 집계를 수행함
- 따라서 파티션별 집계 결과 수와 파티션 수를 곱해 결과로 반환되는 로우 수를 계산할 수 있음  
(파티션별로 집계를 수행한 결과는 true, false, null 값의 통계를 반환함. 파티션이 2개이므로 이 둘을 곱해 6이라는 값을 얻을 수 있음)

![img](https://github.com/koni114/Spark/blob/main/Spark_The_Definitive_Guide/imgs/Spark_monitoring3.JPG)

- 마지막 스테이지는 이전 스테이지의 결과에 대한 집계를 수행
- 이전 스테이지의 두 개 결과 파티션을 결합해 예제 쿼리의 결과로 세 개 로우를 반환

![img](https://github.com/koni114/Spark/blob/main/Spark_The_Definitive_Guide/imgs/Spark_monitoring4.JPG)

- Spark Job의 실행 과정을 알아보기 위해 Jobs 탭에서 2번 Job을 클릭함
- [그림 18-7]에서 볼 수 있듯이 잡은 세 개의 스테이지로 나뉘어 있음(SQL 탭에서 본 것과 일치) 

![img](https://github.com/koni114/Spark/blob/main/Spark_The_Definitive_Guide/imgs/Spark_monitoring5.JPG)

- 모든 스테이지는 [그림 18-6]에서 봤던 내용과 거의 비슷한 정보를 가지고 있음
- Description 링크 중 하나를 클릭하면 Stage에 대한 자세한 내용을 확인할 수 있음
- 이 Job은 3개의 스테이지로 구성되어 있으며 각각 8, 2, 그리고 200개의 테스크를 실행했음
- Stage를 알아보기 전에 어떻게 이처럼 많은 수의 태스크가 생성되었는지 자세히 살펴보자
- 첫 번째 스테이지는 8개의 태스크를 가짐  
  CSV 파일은 분할 가능하기 때문에 Spark는 작업을 나눌 수 있음  
  Spark는 작업을 머신의 여러 코어에 비교적 고르게 배분함  
  이 동작은 클러스터 영역에서 발생하며 사용자가 데이터를 저장하는 방식인 파일 저장 방법과 관련된 중요한 최적화 요소
-  다음 스테이지는 데이터를 두 개의 파티션으로 나누기 위해 repartition 명령을 사용했으므로 두 개의 테스크를 가짐
- 셔플 파티션의 기본값은 200이므로 마지막 스테이지는 200개의 태스크를 가짐
- 8개의 태스크를 가진 첫 번째 스테이지를 클릭해 더 상세한 정보를 확인할 수 있음
- 아래 그림의 상단의 `Summary Metrics` 부분에서는 다양한 매트릭에 관한 요약 통계를 제공
- 균일하지 않게 분산된 값을 눈여겨보아야 함
- 이번 예제는 전체적으로 값이 고르게 분포되어 있음
- 하단의 표로 익스큐터별 통계를 확인할 수 있음. 익스큐터별 통계는 특정 익스큐터가 워크로드를 처리하는 데 어려움을 겪고 있는지 판단할 때 유용하게 사용됨
- 대다수의 사용자와 관련이 없을 수 있지만 더 상세한 메트릭스 정보를 확인할 수도 있음

![img](https://github.com/koni114/Spark/blob/main/Spark_The_Definitive_Guide/imgs/Spark_monitoring6.JPG)

#### 기타 Spark UI 탭
- 나머지 Spark UI 탭은 명확한 의미의 이름을 가진 'Storage', 'Environement', 그리고 'Executors' 임
- Storage 탭은 클러스터에 캐시된 RDD나 DataFrame 관련된 정보를 제공하며 시간이 지나 캐시된 데이터가 사라졌는지 확인 가능
- Environment 탭은 클러스터에 설정된 다양한 스파크 속성 뿐만 아니라 Scala나 Java에 관련된 속성 등 런타임 환경 관련 정보를 제공

#### Spark UI 설정하기
- 다양한 속성을 사용해 Spark UI를 설정할 수 있음
- Spark UI 설정은 접근 제어 활성화 같은 네트워크 관련 속성이 대다수를 차지하며  
  Spark UI의 동작 방식을 설정할 수도 있음(예) 잡, 스테이지, 태스크 정보의 저장 개수 설정)
- 자세한 내용은 스파크 공식 문서의 스파크 UI 설정 표를 참고하자

### 18.4.1 Spark REST API
- 스파크 UI 외에도 REST API로 스파크의 상태와 메트릭을 확인할 수 있음
- REST API의 주소는 http://localhost:4040/api/v1 
- Spark에서 제공하는 시각화 및 모니터링 도구는 REST API를 기반으로 만들어짐  
- 대부분의 REST API는 Spark UI와 동일한 정보를 제공하지만 SQL 관련 정보는 제공하지 않음
- 만약 Spark UI에서 볼 수 있는 정보를 기반으로 사용자 정의 리포트 솔루션을 구축하려면  
  REST API를 사용해야 함

### 18.4.2 Spark UI 히스토리 서버
- Spark UI는 SparkSession가 실행되는 동안 사용할 수 있음 
- 정상적으로 종료되거나 비정상적으로 종료된 애플리케이션의 정보를 확인하려면 스파크 히스토리 서버를 이용해야 함
- 이벤트 로그를 저장하도록 스파크 애플리케이션을 설정하면 스파크 히스토리 서버를 이용해 Spark UI와 REST API를 재구성 할 수 있음
- 스파크 공식 문서의 Spark 히스토리 서버 사용 방법에서 최신 정보를 얻을 수 있음
- Spark 히스토리 서버를 사용하려면 특정 경로에 이벤트 로그를 저장하도록 Spark application을 설정해야 함
- 이 기능을 사용하려면 `spark.eventLog.enabled` 속성을 true로 설정하고 `spark.eventLog.dir` 속성에 이벤트 로그 저장 경로를 지정해야함
- 이벤트 로그가 저장되면 스파크 히스토리 서버를 스탠드얼론 애플리케이션 형태로 실행할 수 있음
- Spark 히스토리 서버는 저장된 이벤트 로그를 기반으로 웹 UI를 자동으로 재구성함
- 일부 클러스터 매니저와 클라우드 서비스에서는 로깅을 자동으로 설정하고 히스토리 서버를 기본적으로 실행함
- 다양한 속성을 사용해 스파크 히스토리 서버를 설정할 수 있음

## 18.5 디버깅 및 스파크 응급 처치
- 이번 절에서는 Spark 디버깅 및 Spark 응급 처치법에 대해서 알아보자
- 이를 위해 Spark 내부에서 발생하는 문제(ex) OutOfMemoryError)와 사용자가 경험할 수 있는 증상(ex) 느린 태스크)를 포함해 Spark Job에서 발생할 수 있는 다양한 문제를 알아보자

### 18.5.1 Spark 애플리케이션이 시작되지 않는 경우
- 이 문제는 자주 발생할 수 있음. 특히 신규 클러스터 매니저나 환경을 사용하는 경우에 자주 발생

#### 징후와 증상
- Spark Job이 시작되지 않음
- Spark UI가 드라이버 노드를 제외한 클러스터의 노드 정보를 전혀 표시하지 않음
- Spark UI가 잘못된 정보를 표시하는 것 같음

#### 잠재적 대응법
- 주로 클러스터나 사용자 애플리케이션의 실행에 필요한 자원을 적절하게 설정하지 않았을 때 발생
- 분산 환경에서 동작하는 Spark는 네트워크, 파일 시스템, 기타 자원과 관련해 몇 가지 상황 예측 가능
- Spark 클러스터 구축 과정시 잘못 설정했다면 드라이버와 익스큐터 간에 통신이 제대로 이루어지지 않을 수 있음
- 이 현상은 <b>IP를 잘못 입력했거나, 포트가 열리지 않은 경우</b>에 발생할 수 있으며 대부분 클러스터 영역, 머신, 설정과 관련된 문제
- 또한 사용자 애플리케이션에서 익스큐터 자원을 클러스터 유휴 자원 이상으로 요청하는 경우가 있음
- 이런 경우 드라이버는 익스큐터가 실행될 때까지 무한정 대기함
- 설정한 포트로 클러스터 머신 간에 통신할 수 있는지 확인해야 함. 만약 보안 요건이 엄격하지 않다면 워커 노드 간의 모든 포트를 여는 것이 좋음
- Spark 자원 설정 확인, 클러스터 매니저 확인 필요. 그런 다음 간단한 Spark application을 실행해 정상적으로 동작하는지 확인
- 클러스터 매니저가 제공할 수 있는 메모리 자원 이상으로 익스큐터의 메모리 자원을 요청하는 경우가 발생함  
따라서 <b>클러스터 매니저의 UI로 유휴 자원을 확인한 다음 spark-submit 명령에 할당할 메모리 설정 </b>

### 18.5.2 Spark 애플리케이션 실행 전에 오류 발생한 경우
- 이 문제는 새로운 애플리케이션을 개발해 클러스터에서 실행할 때 발생할 수 있음

#### 징후와 증상
- 명령이 전혀 실행되지 않으며 오류 메세지가 출력됨
- Spark UI에서 Job, Stage, Task의 정보를 확인할 수 없음

#### 잠재적 대응법
- Spark UI의 Environment 탭에서 애플리케이션 정보가 올바른지 확인한 다음 다음 코드 검토
- 단순한 오타나 잘못된 컬럼명을 사용하는 경우가 많으며 <b>Spark 실행 계획(DataFrame API를 사용한 경우)을 만드는 과정에서 오류 발생</b>
- <b>잘못된 입력 파일 경로, 필드명을 사용하는 것</b>과 같이 코드상에 문제가 없는지 확인하기 위해 Spark가 반환하는 오류를 살펴봐야 함
- 클러스터의 드라이버, 워커, 사용하는 저장소 시스템 간의 연결 상태를 다시한 번 확인
- 잘못된 버전의 저장소 접속용 라이브러리를 사용할 수 있으므로  라이브러리나 클래스패스를 확인  
  이 문제가 재현될 때까지 사용자 애플리케이션 로직을 하나씩 제거하면서 원인을 찾아보자  
  예를 들어 데이터셋을 하나만 읽도록 애플리케이션 수행

### 18.5.3 Spark 애플리케이션 실행 중에 오류가 발생한 경우
- 실행 중인 Spark 애플리케이션은 다양한 상황에서 오류가 발생할 수 있음
- 이미 클러스터를 사용 중이거나 사용자 Spark 애플리케이션을 실행하는 중에 발생
- 또한 특정 주기로 실행되는 예약 작업이나 일부 대화형 탐색에서 발생할 수 있음

#### 징후와 증상
- 하나의 Spark Job이 전체 클러스터에서 성공적으로 실행되지만 다음 Job은 실패함
- 여러 단계로 처리되는 쿼리의 특정 단계가 실패함
- 어제 정상 동작한 예약 작업이 오늘은 실패함
- 오류 메세지를 해석하기 어려움

#### 잠재적 대응법
- 데이터가 존재하는지 또는 데이터가 올바른 포맷인지 확인  
 포맷이 변경되었거나 일부 처리 과정이 변경되어 사용자 애플리케이션이 의도하지 않은 결과 초래
- 만약 쿼리 실행 즉시 오류가 발생한다면(ex) 태스크가 실행되기 전에 발생) 쿼리 실행 계획을 만드는 단계에서 발생한 오류일 가능성이 높음
- 즉, 쿼리에 잘못된 컬럼명을 입력하였거나 컬럼, 뷰, 테이블이 존재하지 않을 수 있음
- 스택 트레이스(Stack trace)를 분석해 어떤 컴포넌트가 연관되어 있는지(ex) 어떤 연산자와 스테이지가 실행 중이였는지) 원인을 파악해야 함
- 애플리케이션의 코드를 줄여가면서 데이터 포맷, 입력 데이터 확인
- Job의 태스크가 잠시 실행되다가 비정상적으로 종료된다면 입력 데이터 자체의 문제(ex) schema 설정오류, 특정 로우가 스키마 형태와 일치하지 않는 경우)일 수 있음  
ex) null 값을 허용하지 않게 스키마를 정의했지만 null이 들어온 경우 트랜스포메이션은 오류 발생
- 데이터 처리 코드에서 오류 발생할 수 있음. 오류가 발생하면 Spark Log에 오류 내용이 출력됨  
  그리고 Spark UI에서 태스크의 상태가 'failed'로 표시됨  
  로그 파일을 분석해 오류 발생 시 어떤 작업이 진행 중이였는지 확인 가능하며, 로그를 남기도록 추가해 처리 중인 데이터 레코드를 파악해봐야 함

### 18.5.4 느리거나 뒤처진 태스크
- 태스크가 느리거나 뒤쳐지는 현상은 애플리케이션을 최적화할 때 매우 흔하게 발생함
- 머신 간의 작업이 균등하게 분배되지 않거나(데이터 치우침 skew) 특정 머신이 다른 머신에 비해 처리 속도가 느린 경우에도 발생함  

#### 징후와 증상
- 다음은 태스크가 느리거나 뒤쳐지는 현상과 관련된 증상
  - Spark 스테이지에서 대부분의 태스크가 정상적으로 수행. 몇 태스크만 남아있고 오랫동안 수행됨
  - Spark UI에서 느린 태스크를 확인할 수 있으며, 동일한 데이터셋을 다룰 때 항상 발생
  - 여러 스테이지를 번갈아 가며 두 번째 증상과 같은 현상 발생
  - Spark application을 실행하는 머신 수를 늘려도 상황이 개선되지 않고 여전히 특정 태스크가 다른 태스크에 비해 훨씬 오래 걸림
  - Spark 매트릭을 보면 특정 익스큐터가 다른 익스큐터에 비해 훨씬 많은 데이터를 읽거나 쓰고 있음을 알 수 있음

#### 잠재적 대응법
- <b>느린 태스크를 낙오자(straggler)라 부르기도 함</b>
- 다양한 이유로 느린 태스크가 발생하지만 DataFrame이나 RDD 파티션에 데이터가 균등하게 분할되지 않은 경우에 발생
- 이 현상이 발생하면 특정 익스큐터가 다른 익스큐터에 비해 훨씬 많은 양의 데이터를 처리하고 있음  
예를 들어 `group-by-key` 연산 수행 시 특정 키가 다른 키에 비해서 훨씬 많은 양의 데이터를 가진 경우에 발생
- Spark UI를 보면 일부 노드의 셔플 데이터가 다른 노드에 비해 월등히 큰 것을 확인할 수 있음  
- 파티션별 데이터양을 줄이기 위해 파티션 수를 증가시켜볼 수 있음
- 다른 컬럼을 조합해 파티션을 재분배 하는 것도 하나의 방법  
  데이터의 치우침이 심한 ID 컬럼을 파티셔닝하거나, null값이 많은 경우 치우침 현상이 발생할 수 있으므로, null 값을 먼저 필터링하는 것이 합리적일 수 있음
- 익스큐터의 메모리를 증가시켜 볼 수 있음
- 특정 머신에서 수행되는 익스큐터에 문제가 있는지 모니터링하고, 해당 머신의 다른 잡에서도 문제가 발생하는지 확인. 이는 특정 클러스터의 disk가 꽉찼을 수도 있음
- 조인이나 집계에 문제가 발생할 수 있음
- UDF 구현시 쓸모없는 로직이 있는지 파악하고, 되도록이면 DataFrame 코드로 변환
- UDF, UDAF(사용자 정의 집계 함수)가 적당한 크기의 데이터를 사용해 실행되는지 확인해야함  
  집계 연산은 공통 키와 관련된 많은 데이터를 메모리에 적재함. 즉 집계 연산을 수행하는 익스큐터는 다른 익스큐터에 비해 많은 훨씬 많은 작업을 수행
- Dataset 사용시 레코드를 사용자 정의 함수의 자바 객체로 변환하기 위해 수많은 객체를 생성하므로 가비지 컬렉션이 빈번하게 발생할 수 있음. Dataset을 사용한다면 spark UI의 가비지 컬렉션 매트릭이 느린 태스크와 관련 있는지 확인

### 18.5.5 느린 집계 속도
- 집계 연산 속도가 느리다면 18.5.4절 '느리거나 뒤처진 태스크'에서 설명한 문제점을 먼저 검토해야함

#### 징후와 증상
- `groupBy` 호출 시 느린 태스크가 발생
- 집계 처리 속도 이후 Job도 느림

#### 잠재적 대응법
- job에서 사용하는 데이터가 특정 키에 치우쳐 있다면 연산 속도가 느려질 것임
- 집계 연산 전에 파티션 수를 증가시키면 태스크별로 처리할 키 수를 줄일 수 있음
- 익스큐터의 메모리를 증가시킨 경우 데이터가 많은 키를 처리하는 익스큐터는 다른 키를 처리하는 익스큐터에 비해 여전히 느릴 수 있음. 하지만 데이터를 디스크에 저장하는 빈도를 줄일 수 있어 이전보다 빠르게 처리 가능
- 집계 처리가 끝나고 이어서 실행되는 태스크가 느리다면 집계 처리된 데이터셋에 불균형 현상이 남아있어서 그럴 수 있으므로, `repartition` 명령을 추가하자
- 필요한 데이터만 이용해서(filter) 집계 연산 수행할 수 있음  
  구조적 API를 사용하는 경우 Spark의 쿼리 옵티마이저가 자동으로 실행함
- null 값 대신에 "" 또는 "EMPTY" 같은 값을 대체 값으로 사용하는지 확인  
  Spark는 Job 실행 전 null값을 건너 띄는 최적화를 수행하는데, 다른 값으로 대체되어 있으면 최적화 수행을 하지 못함
- 특정 집계 함수는 성능이 매우 느림. 예를 들어 집계 함수인 `collect_list`와 `collect_set`은 일치하는 모든 객체를 드라이버에 전송하기 때문에 아주 느리게 동작함

### 18.5.6 느린 조인 속도
- 조인과 집계는 모두 셔플을 유발하기 때문에 동일한 증상과 대응법을 가짐

#### 징후와 증상
- 조인 스테이지의 처리 시간이 오래 걸림.
  하나 이상의 태스크가 여기에 해당할 수 있음 
- 조인 전후의 스테이지는 정상적으로 동작함

#### 잠재적 대응법
- 많은 조인 연산은 다른 조인 타입으로 변경해 최적화 연산을 수행할 수 있음
- 조인 순서를 변경해 잡의 처리 속도가 올라가는지 테스트가 필요  
  일부 조인은 많은 양의 데이터를 걸러낼 수 있으므로 이 작업을 먼저 시도해 보는 것이 좋음
- 조인을 수행하기 전 데이터셋을 분할하면 클러스터 노드 간 이동을 줄일 수 있음  
  특히 동일한 데이터셋이 여러 조인 연산에서 사용된다면 더욱 유용  
  또한 다양한 사전조인 파티셔닝(prejoin partitioning) 기법을 실험해봐야 함  
  <b>다시 한번 강조하지만 조인 연산은 셔플 부하를 일으킴</b>
- 데이터 치우침 현상은 느린 조인을 유발할 수 있음  
  앞 절에서 알아본 것처럼 Spark application이나 익스큐터의 자원 할당량을 늘리는 것이 도움이 됨
- 모든 필터와 SELECT 구문이 조인 연산보다 앞에서 수행되도록 해야함
- null 값이 다른 값으로 대체되어 사용되지는 않는지 확인
- Spark는 조인 대상 테이블 중 하나가 작은 경우 브로드캐스트 조인을 사용해야함 또는 Spark의 통계 수집 명령을 사용해 테이블을 분석해야 함

### 18.5.7 느린 읽기와 쓰기 속도
- 느린 I/O는 진단이 어려울 수 있음
- 특히 네트워크 파일 기반 시스템을 사용하는 경우 더 어려움

#### 징후와 증상
- 분산 파일 시스템이나 외부 시스템의 데이터를 읽는 속도가 느림
- 네트워크 파일 시스템이나 blob 저장소에 파일을 쓰는 속도가 느림

#### 잠재적 대응법 
- Spark의 투기적 실행(`spark.speculation` 속성을 `true`로 설정)을 사용하면 느린 읽기와 쓰기 속도를 개선하는 데 도움이 될 수 있음  
이 기능은 첫 번째 태스크에서 발생한 문제가 일시적인지 확인하기 위해 동일한 연산을 수행하는 태스크를 추가로 실행  
투기적 실행은 강력한 기능이며 일관성을 보장하는 파일 시스템과 함께 사용하는 것이 좋음  
그러나 아마존 S3 같이 궁극적 일관성 방식을 사용하는 클라우드 서비스를 저장소로 사용하면 중복 데이터가 발생할 수 있음  
따라서 사용 중인 저장소 시스템의 커넥터가 쓰기 일관성을 지원하는지 확인  
- Spark 클러스터와 저장소 시스템 간의 네트워크 대역폭이 충분하지 않을 수 있으므로  
  네트워크 성능에 문제가 없는지 반드시 확인해야 함
- 단일 클러스터에서 Spark HDFS와 같은 분산 파일 시스템을 함께 구성하려면 클러스터의 노드마다 스파크와 분산 파일 시스템 모두 동일한 호스트명을 인식하는지 확인

### 18.5.8 드라이버 OutOfMemoryError 또는 응답 없음
- 드라이버 OutOfMemoryError는 Spark 애플리케이션이 비정상적으로 종료되므로 매우 심각한 문제
- 드라이버에 너무 많은 데이터를 전송해 메모리를 모두 소비한 경우에 발생

#### 징후와 증상
- Spark 애플리케이션이 응답하지 않거나, 비정상적으로 종료
- 드라이버 로그에 OutOfMemoryError 또는 가비지 컬렉션 관련한 메세지가 출력됨
- 명령이 장시간 실행되거나 실행되지 않음
- 드라이버 JVM의 메모리 사용량이 많음

#### 잠재적 대응법
- 사용자 코드에서 `collect` 메소드 같은 연산을 실행해 너무 큰 데이터셋을 드라이버에 전송하려고 시도했을 수 있음
- 브로드캐스트하기에 너무 큰 데이터를 브로드캐스트 조인에 사용했을 수 있음
- Spark의 최대 브로드캐스트 조인 설정을 이용해 브로드캐스트할 크기를 제어할 수 있음
- 장시간 실행되는 어플리케이션은 드라이버의 많은 객체를 생성해 해제하지 못할 수 있음  
  자바의 jmap 도구를 이용해 힙 메모리의 히스토그램을 확인 가능  
  이 도구에서 가장 많이 메모리를 차지하는 객체를 찾는데 유용  
  그러나 jmap 사용시 잠시 JVM이 중단될 수 있으므로 조심해야함
- 더 많은 데이터를 다룰 수 있도록 드라이버의 가용 메모리 증가
- JVM 메모리 부족 현상은 파이썬과 같은 다른 언어와 같이 사용하는 경우 발생할 수 있음  
  두 언어 간의 데이터 변환 과정에서 과도한 메모리를 사용하기 때문  
  선택한 언어로 인해 발생했는지 확인하기 위해 드라이버 노드에 더 적은 양의 데이터를 전송해봄  
  아니면 드라이버 메모리에 모으지 않고 파일로 저장해 볼 수 있음
- SQL JDBC 서버와 노트북 환경을 이용해 다른 사용자와 SparkContext를 공유하는 상황이라면  
  여러 사용자가 동시에 대량의 데이터를 드라이버 메모리로 전송할 수 있는 명령을 실행하지 못하도록 막아야 함

### 18.5.9 익스큐터 OutOfMemoryError 또는 응답 없음
- 문제의 근본 원인에 따라 다르지만 Spark 애플리케이션이 이런 문제를 자동으로 해결 가능

#### 징후와 증상
- 익스큐터 로그에 OutOfMemoryError 또는 가비지 컬렉션과 관련된 메세지가 출력되며 Spark UI에서도 확인할 수 있음
- 익스큐터가 비정상적으로 종료되거나 응답하지 않음
- 특정 노드의 느린 태스크가 복구되지 않음

#### 잠재적 대응법
- 익스큐터의 가용 메모리, 익스큐터 수 증가
- 파이썬 설정을 변경해 PySpark 워커의 크기를 증가시킴
- 익스큐터 로그에 가비지 컬렉션 오류가 발생했는지 확인, 실행 중인 태스크의 일부가 너무 많은 객체를 생성하고 있어 가비지 컬렉션이 발생했을 수 있음  
특히 UDF를 사용하는 경우에 발생 확률이 높음  
데이터 파티션을 재분배하면 문제 해결이 가능
- null값이 다른 값으로 대체되지는 않았는지 확인 
- 가능하면 사용자 정의 함수의 사용을 줄이고 Spark의 구조적 API를 더 많이 사용해야 함
- jmap 도구를 사용하여 가장 많은 메모리를 사용하고 있는 클래스 확인
- 키-값 저장소 같이 다른 워크로드를 처리하는 노드에 익스큐터가 위치한다면 Spark Job을 다른 작업과 분리해야함 

### 18.5.10 의도하지 않은 null 값이 있는 결과 데이터
####
- 트랜스포메이션이 실행된 결과에 의도치 않은 null값 발생
- 잘 동작하던 운영 환경의 예약 작업이 더는 동작하지 않거나 정확한 결과를 생성하지 못함

#### 잠재적 대응법 
- 비즈니스 로직을 변경하지 않았다면 데이터 포맷이 변경되었을 수 있음
- 어큐뮬레이터를 사용해 레코드나 특정 데이터 타입의 수를 확인 가능  
  이 방식으로 레코드를 건너띄는 오류도 분석 가능  
  예를 들어 특정 포맷의 데이터를 파싱하던 중 일부 데이터가 파싱되지 않았다면 이 방법이 유용할 수 있음  
  대부분의 경우 원시 데이터를 파싱할 때 개수를 세기 위한 용도로 어큐뮬레이터가 탑재된 사용자 정의 함수를 사용  
  어큐뮬레이터로 정상과 비정상 레코드 수를 확인할 수 있음 결과에 따라 상황에 맞는 명령을 수행할 수 있음
- 트랜스포메이션이 실제 유효한 쿼리 실행 계획을 생성하는지 확인  
  Spark SQL에서 암시적 형변환을 수행하는 경우 혼란스러운 결과가 반환될 수 있음  
  ex) SELECT 5 * "23"은 '23' -> 23으로 변환되면서 115를 반환함   
  하지만 5 * " "는 null이 되므로 null 값 반환
- 항상 중간 데이터가 원하는 포맷으로 만들어졌는지 확인하고 최종 쿼리 실행 계획에 있는 모든   
  CAST 연산을 찾아 확인해야 함

### 18.5.11 디스크 공간 없음 오류
#### 징후와 증상
- 'no space left on disk' 오류 메세지와 함께 잡이 실패함

#### 잠재적 대응법
- 작업 노드의 디스크를 늘리거나 클라우드 환경의 외부 저장소를 추가해 디스크 확보 가능
- 제한된 용량의 저장소를 가진 클러스터 사용의 경우 데이터 치우침 현상이 발생하면   
  일부 노드의 저장소 공간이 모두 소진될 수 있음

### 18.5.12 직렬화 오류
#### 징후와 증상
- 직렬화 오류와 함께 잡이 실패함

#### 잠재적 대응법
- 구조적 API를 사용하는 경우 직렬화 오류는 거의 나타나지 않음
- 하지만 UDF, RDD를 이용해 개발된 사용자 정의 로직을 수행하는 익스큐터에서는 발생할 수 있음
- 이러한 익스큐터로 직렬화를 시도하는 태스크나 공유하려는 데이터를 직렬화할 수 없는 경우에 발생
- 이러한 문제가 발생하는 경우 직렬화 대상 사용자 클래스를 실제로 등록해 직렬화 성공 여부를 확인해야 함


## 용어 정리
- blob 저장소
  - AZure 의 blob 저장소. 구조화되지 않는 많은 데이터를 http, https 방식을 통해서 접근할 수 있는 서비스
- 투기적 실행(speculative execution)
  - 하나의 Job을 중복된 태스크로 구성하여 동시에 수행시키는 작업
  - 같은 데이터를 중복하여 복사하기 때문에 많은 리소스가 소요됨
  - 동일한 태스크를 여러 노드에서 실행시키므로서 특정 노드가 느리더라도(장비 노후 또는 기타 문제로) 다른 노드에서 먼저 끝나면 해당 결과를 사용하고 나머지 노드는 중지시킴
- 메트릭(Metric)
  - 측정, 기준을 말함


